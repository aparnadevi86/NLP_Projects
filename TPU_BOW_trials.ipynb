{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bag of words implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import collections\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14417 entries, 0 to 14416\n",
      "Data columns (total 9 columns):\n",
      "Description    14415 non-null object\n",
      "Log Time       14362 non-null object\n",
      "Type           14362 non-null object\n",
      "Priority       14362 non-null object\n",
      "Status         14362 non-null object\n",
      "Area           14038 non-null object\n",
      "Site           14214 non-null object\n",
      "Unit           5722 non-null object\n",
      "TCV_LP_SP      0 non-null float64\n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 1013.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "log = pd.read_excel(\"D:\\\\next_word_prediction\\\\TPU_Operation_Log.xlsx\")\n",
    "print(log.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Log Time</th>\n",
       "      <th>Type</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>Area</th>\n",
       "      <th>Site</th>\n",
       "      <th>Unit</th>\n",
       "      <th>TCV_LP_SP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xcxcxcxvxcvcx</td>\n",
       "      <td>October 20, 2017 5:00 PM</td>\n",
       "      <td>Operations</td>\n",
       "      <td>Low</td>\n",
       "      <td>Open</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adfsdsafdsafdsaf</td>\n",
       "      <td>September 27, 2017 4:35 PM</td>\n",
       "      <td>Operations</td>\n",
       "      <td>Low</td>\n",
       "      <td>Open</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this was changed][][] by dawkldmawmkoal;m|||</td>\n",
       "      <td>September 08, 2017 12:00 AM</td>\n",
       "      <td>Operations</td>\n",
       "      <td>Low</td>\n",
       "      <td>Open</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>September 08, 2017 11:32 AM</td>\n",
       "      <td>Operations</td>\n",
       "      <td>Low</td>\n",
       "      <td>Open</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Critical</td>\n",
       "      <td>August 22, 2017 4:28 PM</td>\n",
       "      <td>Oil Analysis Ferrorgraphy</td>\n",
       "      <td>Low</td>\n",
       "      <td>Open</td>\n",
       "      <td>CFB</td>\n",
       "      <td>Cogen</td>\n",
       "      <td>CFB1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tes Log</td>\n",
       "      <td>July 05, 2017 11:41 AM</td>\n",
       "      <td>Operations</td>\n",
       "      <td>Low</td>\n",
       "      <td>Open</td>\n",
       "      <td>BUB</td>\n",
       "      <td>Cogen</td>\n",
       "      <td>BUB1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Oil analysis results are Normal. entered forxx...</td>\n",
       "      <td>January 10, 2017 10:39 AM</td>\n",
       "      <td>Oil Analysis Ferrorgraphy</td>\n",
       "      <td>Low</td>\n",
       "      <td>Open</td>\n",
       "      <td>CFB</td>\n",
       "      <td>Cogen</td>\n",
       "      <td>CFB1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>awdfas</td>\n",
       "      <td>March 21, 2017 10:29 AM</td>\n",
       "      <td>Operations</td>\n",
       "      <td>Low</td>\n",
       "      <td>Open</td>\n",
       "      <td>SATTEST</td>\n",
       "      <td>Cogen</td>\n",
       "      <td>Test&amp;Unit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bobbin test bub status log</td>\n",
       "      <td>March 16, 2017 2:02 PM</td>\n",
       "      <td>BUB Status Log</td>\n",
       "      <td>Low</td>\n",
       "      <td>Open</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cogen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test log</td>\n",
       "      <td>March 13, 2017 1:41 PM</td>\n",
       "      <td>BUB Status Log</td>\n",
       "      <td>Low</td>\n",
       "      <td>Open</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cogen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  \\\n",
       "0                                      xcxcxcxvxcvcx   \n",
       "1                                   adfsdsafdsafdsaf   \n",
       "2       this was changed][][] by dawkldmawmkoal;m|||   \n",
       "3                                               test   \n",
       "4                                           Critical   \n",
       "5                                            Tes Log   \n",
       "6  Oil analysis results are Normal. entered forxx...   \n",
       "7                                             awdfas   \n",
       "8                         bobbin test bub status log   \n",
       "9                                           test log   \n",
       "\n",
       "                      Log Time                       Type Priority Status  \\\n",
       "0     October 20, 2017 5:00 PM                 Operations      Low   Open   \n",
       "1   September 27, 2017 4:35 PM                 Operations      Low   Open   \n",
       "2  September 08, 2017 12:00 AM                 Operations      Low   Open   \n",
       "3  September 08, 2017 11:32 AM                 Operations      Low   Open   \n",
       "4      August 22, 2017 4:28 PM  Oil Analysis Ferrorgraphy      Low   Open   \n",
       "5       July 05, 2017 11:41 AM                 Operations      Low   Open   \n",
       "6    January 10, 2017 10:39 AM  Oil Analysis Ferrorgraphy      Low   Open   \n",
       "7      March 21, 2017 10:29 AM                 Operations      Low   Open   \n",
       "8       March 16, 2017 2:02 PM             BUB Status Log      Low   Open   \n",
       "9       March 13, 2017 1:41 PM             BUB Status Log      Low   Open   \n",
       "\n",
       "      Area   Site       Unit  TCV_LP_SP  \n",
       "0      NaN    NaN        NaN        NaN  \n",
       "1      NaN    NaN        NaN        NaN  \n",
       "2      NaN    NaN        NaN        NaN  \n",
       "3      NaN    NaN        NaN        NaN  \n",
       "4      CFB  Cogen       CFB1        NaN  \n",
       "5      BUB  Cogen       BUB1        NaN  \n",
       "6      CFB  Cogen       CFB1        NaN  \n",
       "7  SATTEST  Cogen  Test&Unit        NaN  \n",
       "8      NaN  Cogen        NaN        NaN  \n",
       "9      NaN  Cogen        NaN        NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Description', 'Log Time', 'Type', 'Priority', 'Status', 'Area', 'Site',\n",
      "       'Unit', 'TCV_LP_SP'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(log.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations                            12839\n",
      "Process Steam and Water Status Log      725\n",
      "BUB Status Log                          148\n",
      "Backup Valve Status Log                 145\n",
      "STG Status Log                          145\n",
      "CFB Status Log                          145\n",
      "Summary Log                             144\n",
      "General                                  43\n",
      "Safety                                   22\n",
      "Oil Analysis Ferrorgraphy                 3\n",
      "Oil Analyis Spectrography                 3\n",
      "Name: Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(log['Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low     14353\n",
      "High        9\n",
      "Name: Priority, dtype: int64\n",
      "\n",
      "\n",
      "Information    7270\n",
      "Closed         6313\n",
      "Open            779\n",
      "Name: Status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(log['Priority'].value_counts())\n",
    "print('\\n')\n",
    "print(log['Status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log['Area'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = log.loc[log['Description'].notnull(), 'Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Process log descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Extract words from each line (tokenize). Remove stop words and punctuations.\n",
    "\n",
    "Step 2: Loop through each line, tokenising and adding to vocabulary list.\n",
    "\n",
    "Step 3: Count the total items and unique items in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(sentence):\n",
    "    #stop_words = ['.',',',';','&','a','as','the','so','and','were','have','been','from','that','of','in','only','with','to']\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(sentence)\n",
    "    words_cleaned = [w.lower() for w in words if w not in stop_words and re.match('^[a-z]+', w)] #and w not in string.punctuation]\n",
    "    stemmer = PorterStemmer()\n",
    "    vocab_stemmed = [stemmer.stem(word) for word in words_cleaned]\n",
    "    return vocab_stemmed\n",
    "\n",
    "def get_vocab(sentences):\n",
    "    vocab = []\n",
    "    for sentence in sentences:\n",
    "        words = extract_words(sentence)\n",
    "        vocab.extend(words)\n",
    "    vocab = sorted(vocab)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all words\n",
    "vocab = get_vocab(data)\n",
    "# unique words\n",
    "vocab_set = set(sorted(vocab))\n",
    "print('There are', len(vocab), ' words in the vocab with', len(vocab_set), ' unique words in the set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = nltk.FreqDist(vocab)\n",
    "print(distr.most_common(25))\n",
    "print(distr['pump'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = extract_words(data[10])\n",
    "tagged = nltk.pos_tag(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pump', 'JJ'),\n",
       " ('start', 'NN'),\n",
       " ('per', 'IN'),\n",
       " ('stop', 'NN'),\n",
       " ('stop', 'NN')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized\n",
    "tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(sentence, words):\n",
    "    sentence_words = extract_words(sentence)\n",
    "    \n",
    "    bag = np.zeros(len(words)) # initialise zero vector\n",
    "    for sw in sentence_words:\n",
    "        for i,word in enumerate(words):\n",
    "            if word == sw: \n",
    "                bag[i] += 1\n",
    "                \n",
    "    return np.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn implementation\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words='english', max_features = 5000) \n",
    "# train_data_features = vectorizer.fit_transform(data[5:20])\n",
    "# vectorizer.transform([\"mm review test critical pump stop oil log hot\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
